{
 "metadata": {
  "name": "",
  "signature": "sha256:7d9ebcffbea3e3a0af45246c13a33050792da03993904cab792e1a4ff025617f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##some temp work\n",
      "\n",
      "#     crawlFile = open('crawlerMap')\n",
      "\n",
      "#     ens = []\n",
      "#     rels = []\n",
      "#     metainfo = {}\n",
      "#     currdict = {}\n",
      "#     curr_ch = '-'\n",
      "\n",
      "#     for line in crawlFile.readlines():\n",
      "#         line = line.strip()\n",
      "#         if line[0]=='#':\n",
      "\n",
      "#             ##adjusting the old one\n",
      "#             if curr_ch=='e':\n",
      "#                 ens.append(currdict)\n",
      "#             elif curr_ch == 'r':\n",
      "#                 rels.append(currdict)\n",
      "\n",
      "#             ##adjusting for the new one\n",
      "#             if line[1]=='e':\n",
      "#                 ##an entity is what we are reading\n",
      "#                 currdict = {}\n",
      "#                 curr_ch='e'\n",
      "#             else:\n",
      "#                 currdict = {}\n",
      "#                 curr_ch='r'\n",
      "#                 ##a relation is what we are reading\n",
      "#         elif curr_ch!='-':\n",
      "#             prop = line[0:line.find(':')].strip()\n",
      "#             value = line[line.find(':')+1:].strip()\n",
      "#             if(prop!='number'):\n",
      "#                 #split\n",
      "#                 value = value.split(',')\n",
      "#                 #strip\n",
      "#                 value = map(str.strip, value)\n",
      "#             currdict[prop] = value\n",
      "#         else:\n",
      "#             prop = line[0:line.find(':')].strip()\n",
      "#             value = line[line.find(':')+1:].strip()\n",
      "#             metainfo[prop] = value\n",
      "#     if curr_ch=='e':\n",
      "#         ens.append(currdict)\n",
      "#     elif curr_ch=='r':\n",
      "#         rels.append(currdict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "[{'graph': ['name'],\n",
        "  'label': ['person'],\n",
        "  'mysql': ['name1'],\n",
        "  'number': '1',\n",
        "  'resolve': ['name1']},\n",
        " {'graph': ['name'],\n",
        "  'label': ['person'],\n",
        "  'mysql': ['name2'],\n",
        "  'number': '2',\n",
        "  'resolve': ['name2']}]"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def crawlerMappings(crawlFile):\n",
      "    \n",
      "    crawlFile = open(crawlFile)\n",
      "\n",
      "    ## format of file:\n",
      "    ## metainfo key value pairs\n",
      "    ## ens\n",
      "    ## rels etc. in order\n",
      "\n",
      "    ens = []\n",
      "    rels = []\n",
      "    metainfo = {}\n",
      "    currdict = {}\n",
      "    curr_ch = '-'\n",
      "\n",
      "    for line in crawlFile.readlines():\n",
      "        line = line.strip()\n",
      "        if line[0]=='#':\n",
      "\n",
      "            ##adjusting the old one\n",
      "            if curr_ch=='e':\n",
      "                ens.append(currdict)\n",
      "            elif curr_ch == 'r':\n",
      "                rels.append(currdict)\n",
      "\n",
      "            ##adjusting for the new one\n",
      "            if line[1]=='e':\n",
      "                ##an entity is what we are reading\n",
      "                currdict = {}\n",
      "                curr_ch='e'\n",
      "            else:\n",
      "                currdict = {}\n",
      "                curr_ch='r'\n",
      "                ##a relation is what we are reading\n",
      "        elif curr_ch!='-':\n",
      "            prop = line[0:line.find(':')].strip()\n",
      "            value = line[line.find(':')+1:].strip()\n",
      "            if(prop!='number' and prop!='from' and prop!='to'):\n",
      "                #split\n",
      "                value = value.split(',')\n",
      "                #strip\n",
      "                value = map(str.strip, value)\n",
      "            currdict[prop] = value\n",
      "        else:\n",
      "            prop = line[0:line.find(':')].strip()\n",
      "            value = line[line.find(':')+1:].strip()\n",
      "            metainfo[prop] = value\n",
      "    if curr_ch=='e':\n",
      "        ens.append(currdict)\n",
      "    elif curr_ch=='r':\n",
      "        rels.append(currdict)\n",
      "    \n",
      "    return metainfo,ens,rels"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import MySQLdb as db\n",
      "import pandas as pd\n",
      "def sqlQuerytoDF(query,ipaddress,database,user,password):\n",
      "    database = db.connect(ipaddress, user, password, database)\n",
      "    df = pd.read_sql(query, database)\n",
      "    return df\n",
      "#df = sqlQuerytoDF(\"select * from political_crawl_jan \" + +\" where resolved = 0 order by id limit 1;\", \"localhost\",\"crawldb\",\"root\",\"yoyo\")\n",
      "#df['name'][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from py2neo import Graph, Node, Relationship\n",
      "\n",
      "def createNodeFromMapping(en,df):\n",
      "    node =  Node()\n",
      "    for label in en['label']:\n",
      "        node.labels.add(label)\n",
      "    for i in range(len(en['graph'])):\n",
      "        node.properties[en['graph'][i]] = df[en['mysql'][i]][0]\n",
      "    return node\n",
      "\n",
      "def createRelFromMapping(rel,startNode,endNode,df):\n",
      "    link =  Relationship(startNode,rel['label'],endNode)\n",
      "    for i in range(len(rel['graph'])):\n",
      "        link.properties[rel['graph'][i]] = df[rel['mysql'][i]][0]\n",
      "    return link"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##some temp work\n",
      "\n",
      "\n",
      "meta,ens,rels = crawlerMappings('crawlerMap2')\n",
      "df = sqlQuerytoDF(\"select * from political_crawl_jan where resolved = 1 order by id limit 1;\", \"localhost\",\"crawldb\",\"root\",\"yoyo\")\n",
      "print len(df)\n",
      "mapNodes = {}\n",
      "mapRels = {}\n",
      "\n",
      "for en in ens:\n",
      "    node = createNodeFromMapping(en,df)\n",
      "    mapNodes[en['number']] = node\n",
      "    print node\n",
      "\n",
      "for rel in rels:\n",
      "    startNode = mapNodes[rel['from']]\n",
      "    endNode = mapNodes[rel['to']]\n",
      "    link = createRelFromMapping(rel,startNode,endNode,df)\n",
      "    mapRels[rel['number']] =link\n",
      "    \n",
      "print mapNodes\n",
      "print mapRels\n",
      "print mapNodes.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n"
       ]
      },
      {
       "ename": "IndexError",
       "evalue": "index out of bounds",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-45-e5dc1ada71f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0men\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mens\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mnode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreateNodeFromMapping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0men\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mmapNodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0men\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'number'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-41-62ce31dde3bd>\u001b[0m in \u001b[0;36mcreateNodeFromMapping\u001b[1;34m(en, df)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0men\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'graph'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproperties\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0men\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'graph'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0men\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mysql'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    507\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 509\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    510\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/index.pyc\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   1421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1422\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1423\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mtslib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value_box\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1424\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1425\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/tslib.so\u001b[0m in \u001b[0;36mpandas.tslib.get_value_box (pandas/tslib.c:14029)\u001b[1;34m()\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/tslib.so\u001b[0m in \u001b[0;36mpandas.tslib.get_value_box (pandas/tslib.c:13796)\u001b[1;34m()\u001b[0m\n",
        "\u001b[1;31mIndexError\u001b[0m: index out of bounds"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mapSqlToGraph(filename):\n",
      "    meta,ens,rels = crawlerMappings(filename)\n",
      "    df = sqlQuerytoDF(\"select * from \"+ meta['tablename']+\" where resolved = 0 order by id limit 1;\", \"localhost\",\"crawldb\",\"root\",\"yoyo\")\n",
      "\n",
      "    if len(df) == 0:\n",
      "        return None, None\n",
      "\n",
      "    mapNodes = {}\n",
      "    mapRels = {}\n",
      "\n",
      "    for en in ens:\n",
      "        node = createNodeFromMapping(en,df)\n",
      "        mapNodes[en['number']] = node\n",
      "\n",
      "    for rel in rels:\n",
      "        startNode = mapNodes[rel['from']]\n",
      "        endNode = mapNodes[rel['to']]\n",
      "        link = createRelFromMapping(rel,startNode,endNode,df)\n",
      "        mapRels[rel['number']] =link\n",
      "    \n",
      "    return mapNodes, mapRels\n",
      "mapSqlToGraph('crawlerMap2')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 47,
       "text": [
        "(None, None)"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##5 nodes with almost same things just to test our work\n",
      "from py2neo import Graph, Node, Relationship\n",
      "\n",
      "username = 'neo4j'\n",
      "password = 'yoyo'\n",
      "server = 'localhost'\n",
      "port = '7474'\n",
      "con_url = 'http://'+username+':'+password+'@'+server+':'+port+'/db/data/'\n",
      "\n",
      "graph = Graph(con_url)\n",
      "\n",
      "\n",
      "def deserializeNode(nodeText):\n",
      "    pos =  nodeText.find(' ')\n",
      "    \n",
      "    #get the labels in a set\n",
      "    startText = nodeText[1:pos]\n",
      "    allLabels = startText.split(':')[1:]\n",
      "    allLabels =  set(allLabels) #set is imp\n",
      "    \n",
      "    #get the props in a dict\n",
      "    endText = nodeText[pos+1:-1]\n",
      "    endTextWB = endText[1:-1]\n",
      "    #print endText\n",
      "    #print endTextWB\n",
      "    propList = endTextWB.split(\",\")\n",
      "    propsDict = {}\n",
      "    for x in propList:\n",
      "        propval = x.split(\":\")\n",
      "        #for handling the single inverted comma problem\n",
      "        prop = propval[0]\n",
      "        val = propval[1]\n",
      "        if val[0]==\"'\" and val[-1]==\"'\":\n",
      "            val=val[1:-1]\n",
      "        #for handling the double inverted comma problem\n",
      "        if val[0]=='\"' and val[-1]=='\"':\n",
      "            val=val[1:-1]\n",
      "        propsDict[prop]=val\n",
      "\n",
      "    \n",
      "    #print propsDict\n",
      "    \n",
      "    #creating the node from parsedText\n",
      "    node = Node()\n",
      "    for x in allLabels:\n",
      "        node.labels.add(x)\n",
      "    for x in propsDict:\n",
      "        node[x] = propsDict[x]\n",
      "    print node\n",
      "    return node\n",
      "node = deserializeNode(nodetxt)\n",
      "#graph.create(node)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(:person {address:\"UP\",contact:\"55467868\",email:\"someing@someone.com\",mynetaid:\"23\",name:\"Naviiin Jindal\"})\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import MySQLdb as db\n",
      "def createUuid(name):\n",
      "    mydb = db.connect(\"localhost\",\"root\", \n",
      "        \"yoyo\",\"flasktemp\")\n",
      "    cursor = mydb.cursor()\n",
      "\n",
      "    ##TODO: get uuidtable in constant config file \n",
      "    cursor.execute(\"insert into uuidtable(name) values('\"+name+\"')\")\n",
      "    mydb.commit()\n",
      "\n",
      "    mydb.close()\n",
      "\n",
      "    return cursor.lastrowid"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def wrapCreateNode(graph, node):\n",
      "    ## use this table\n",
      "    ## this table inside flasktemp for now\n",
      "    ## create table uuidtable(uuid bigint(20) not null auto_increment primary key, name varchar(255));\n",
      "    uuid = createUuid(node['name'])\n",
      "    node['uuid'] = uuid\n",
      "    graph.create(node)\n",
      "    node.pull()\n",
      "    return node\n",
      "nodetxt = '(:businessperson:person {address:\"uttar pradesh\", age:44, email:\"sommeing@naveen.com\",mynetaid:\"23\",name:\"Mr. Naveen\"})'\n",
      "node = deserializeNode(nodetxt)\n",
      "wrapCreateNode(graph,node)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(:businessperson:person {` age`:\"44\",` email`:\"sommeing@naveen.com\",address:\"uttar pradesh\",mynetaid:\"23\",name:\"Mr. Naveen\"})\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "<Node graph=u'http://localhost:7474/db/data/' ref=u'node/10' labels=set([u'person', u'businessperson']) properties={u'name': u'Mr. Naveen', u' age': u'44', u'address': u'uttar pradesh', u'mynetaid': u'23', u' email': u'sommeing@naveen.com', u'uuid': 28}>"
       ]
      }
     ],
     "prompt_number": 38
    }
   ],
   "metadata": {}
  }
 ]
}